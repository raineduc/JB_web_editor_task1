/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(self["webpackChunkJB_task"] = self["webpackChunkJB_task"] || []).push([["vendors-node_modules_typo-js_typo_js"],{

/***/ "./node_modules/typo-js/typo.js":
/*!**************************************!*\
  !*** ./node_modules/typo-js/typo.js ***!
  \**************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var __dirname = \"/\";\n/* globals chrome: false */\n/* globals __dirname: false */\n/* globals require: false */\n/* globals Buffer: false */\n/* globals module: false */\n\n/**\n * Typo is a JavaScript implementation of a spellchecker using hunspell-style \n * dictionaries.\n */\n\nvar Typo;\n\n(function () {\n\"use strict\";\n\n/**\n * Typo constructor.\n *\n * @param {String} [dictionary] The locale code of the dictionary being used. e.g.,\n *                              \"en_US\". This is only used to auto-load dictionaries.\n * @param {String} [affData]    The data from the dictionary's .aff file. If omitted\n *                              and Typo.js is being used in a Chrome extension, the .aff\n *                              file will be loaded automatically from\n *                              lib/typo/dictionaries/[dictionary]/[dictionary].aff\n *                              In other environments, it will be loaded from\n *                              [settings.dictionaryPath]/dictionaries/[dictionary]/[dictionary].aff\n * @param {String} [wordsData]  The data from the dictionary's .dic file. If omitted\n *                              and Typo.js is being used in a Chrome extension, the .dic\n *                              file will be loaded automatically from\n *                              lib/typo/dictionaries/[dictionary]/[dictionary].dic\n *                              In other environments, it will be loaded from\n *                              [settings.dictionaryPath]/dictionaries/[dictionary]/[dictionary].dic\n * @param {Object} [settings]   Constructor settings. Available properties are:\n *                              {String} [dictionaryPath]: path to load dictionary from in non-chrome\n *                              environment.\n *                              {Object} [flags]: flag information.\n *                              {Boolean} [asyncLoad]: If true, affData and wordsData will be loaded\n *                              asynchronously.\n *                              {Function} [loadedCallback]: Called when both affData and wordsData\n *                              have been loaded. Only used if asyncLoad is set to true. The parameter\n *                              is the instantiated Typo object.\n *\n * @returns {Typo} A Typo object.\n */\n\nTypo = function (dictionary, affData, wordsData, settings) {\n\tsettings = settings || {};\n\n\tthis.dictionary = null;\n\t\n\tthis.rules = {};\n\tthis.dictionaryTable = {};\n\t\n\tthis.compoundRules = [];\n\tthis.compoundRuleCodes = {};\n\t\n\tthis.replacementTable = [];\n\t\n\tthis.flags = settings.flags || {}; \n\t\n\tthis.memoized = {};\n\n\tthis.loaded = false;\n\t\n\tvar self = this;\n\t\n\tvar path;\n\t\n\t// Loop-control variables.\n\tvar i, j, _len, _jlen;\n\t\n\tif (dictionary) {\n\t\tself.dictionary = dictionary;\n\t\t\n\t\t// If the data is preloaded, just setup the Typo object.\n\t\tif (affData && wordsData) {\n\t\t\tsetup();\n\t\t}\n\t\t// Loading data for Chrome extentions.\n\t\telse if (typeof window !== 'undefined' && 'chrome' in window && 'extension' in window.chrome && 'getURL' in window.chrome.extension) {\n\t\t\tif (settings.dictionaryPath) {\n\t\t\t\tpath = settings.dictionaryPath;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tpath = \"typo/dictionaries\";\n\t\t\t}\n\t\t\t\n\t\t\tif (!affData) readDataFile(chrome.extension.getURL(path + \"/\" + dictionary + \"/\" + dictionary + \".aff\"), setAffData);\n\t\t\tif (!wordsData) readDataFile(chrome.extension.getURL(path + \"/\" + dictionary + \"/\" + dictionary + \".dic\"), setWordsData);\n\t\t}\n\t\telse {\n\t\t\tif (settings.dictionaryPath) {\n\t\t\t\tpath = settings.dictionaryPath;\n\t\t\t}\n\t\t\telse if (true) {\n\t\t\t\tpath = __dirname + '/dictionaries';\n\t\t\t}\n\t\t\telse {}\n\t\t\t\n\t\t\tif (!affData) readDataFile(path + \"/\" + dictionary + \"/\" + dictionary + \".aff\", setAffData);\n\t\t\tif (!wordsData) readDataFile(path + \"/\" + dictionary + \"/\" + dictionary + \".dic\", setWordsData);\n\t\t}\n\t}\n\t\n\tfunction readDataFile(url, setFunc) {\n\t\tvar response = self._readFile(url, null, settings.asyncLoad);\n\t\t\n\t\tif (settings.asyncLoad) {\n\t\t\tresponse.then(function(data) {\n\t\t\t\tsetFunc(data);\n\t\t\t});\n\t\t}\n\t\telse {\n\t\t\tsetFunc(response);\n\t\t}\n\t}\n\n\tfunction setAffData(data) {\n\t\taffData = data;\n\n\t\tif (wordsData) {\n\t\t\tsetup();\n\t\t}\n\t}\n\n\tfunction setWordsData(data) {\n\t\twordsData = data;\n\n\t\tif (affData) {\n\t\t\tsetup();\n\t\t}\n\t}\n\n\tfunction setup() {\n\t\tself.rules = self._parseAFF(affData);\n\t\t\n\t\t// Save the rule codes that are used in compound rules.\n\t\tself.compoundRuleCodes = {};\n\t\t\n\t\tfor (i = 0, _len = self.compoundRules.length; i < _len; i++) {\n\t\t\tvar rule = self.compoundRules[i];\n\t\t\t\n\t\t\tfor (j = 0, _jlen = rule.length; j < _jlen; j++) {\n\t\t\t\tself.compoundRuleCodes[rule[j]] = [];\n\t\t\t}\n\t\t}\n\t\t\n\t\t// If we add this ONLYINCOMPOUND flag to self.compoundRuleCodes, then _parseDIC\n\t\t// will do the work of saving the list of words that are compound-only.\n\t\tif (\"ONLYINCOMPOUND\" in self.flags) {\n\t\t\tself.compoundRuleCodes[self.flags.ONLYINCOMPOUND] = [];\n\t\t}\n\t\t\n\t\tself.dictionaryTable = self._parseDIC(wordsData);\n\t\t\n\t\t// Get rid of any codes from the compound rule codes that are never used \n\t\t// (or that were special regex characters).  Not especially necessary... \n\t\tfor (i in self.compoundRuleCodes) {\n\t\t\tif (self.compoundRuleCodes[i].length === 0) {\n\t\t\t\tdelete self.compoundRuleCodes[i];\n\t\t\t}\n\t\t}\n\t\t\n\t\t// Build the full regular expressions for each compound rule.\n\t\t// I have a feeling (but no confirmation yet) that this method of \n\t\t// testing for compound words is probably slow.\n\t\tfor (i = 0, _len = self.compoundRules.length; i < _len; i++) {\n\t\t\tvar ruleText = self.compoundRules[i];\n\t\t\t\n\t\t\tvar expressionText = \"\";\n\t\t\t\n\t\t\tfor (j = 0, _jlen = ruleText.length; j < _jlen; j++) {\n\t\t\t\tvar character = ruleText[j];\n\t\t\t\t\n\t\t\t\tif (character in self.compoundRuleCodes) {\n\t\t\t\t\texpressionText += \"(\" + self.compoundRuleCodes[character].join(\"|\") + \")\";\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\texpressionText += character;\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tself.compoundRules[i] = new RegExp(expressionText, \"i\");\n\t\t}\n\t\t\n\t\tself.loaded = true;\n\t\t\n\t\tif (settings.asyncLoad && settings.loadedCallback) {\n\t\t\tsettings.loadedCallback(self);\n\t\t}\n\t}\n\t\n\treturn this;\n};\n\nTypo.prototype = {\n\t/**\n\t * Loads a Typo instance from a hash of all of the Typo properties.\n\t *\n\t * @param object obj A hash of Typo properties, probably gotten from a JSON.parse(JSON.stringify(typo_instance)).\n\t */\n\t\n\tload : function (obj) {\n\t\tfor (var i in obj) {\n\t\t\tif (obj.hasOwnProperty(i)) {\n\t\t\t\tthis[i] = obj[i];\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn this;\n\t},\n\t\n\t/**\n\t * Read the contents of a file.\n\t * \n\t * @param {String} path The path (relative) to the file.\n\t * @param {String} [charset=\"ISO8859-1\"] The expected charset of the file\n\t * @param {Boolean} async If true, the file will be read asynchronously. For node.js this does nothing, all\n\t *        files are read synchronously.\n\t * @returns {String} The file data if async is false, otherwise a promise object. If running node.js, the data is\n\t *          always returned.\n\t */\n\t\n\t_readFile : function (path, charset, async) {\n\t\tcharset = charset || \"utf8\";\n\t\t\n\t\tif (typeof XMLHttpRequest !== 'undefined') {\n\t\t\tvar promise;\n\t\t\tvar req = new XMLHttpRequest();\n\t\t\treq.open(\"GET\", path, async);\n\t\t\t\n\t\t\tif (async) {\n\t\t\t\tpromise = new Promise(function(resolve, reject) {\n\t\t\t\t\treq.onload = function() {\n\t\t\t\t\t\tif (req.status === 200) {\n\t\t\t\t\t\t\tresolve(req.responseText);\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\treject(req.statusText);\n\t\t\t\t\t\t}\n\t\t\t\t\t};\n\t\t\t\t\t\n\t\t\t\t\treq.onerror = function() {\n\t\t\t\t\t\treject(req.statusText);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t\n\t\t\tif (req.overrideMimeType)\n\t\t\t\treq.overrideMimeType(\"text/plain; charset=\" + charset);\n\t\t\n\t\t\treq.send(null);\n\t\t\t\n\t\t\treturn async ? promise : req.responseText;\n\t\t}\n\t\telse if (true) {\n\t\t\t// Node.js\n\t\t\tvar fs = __webpack_require__(/*! fs */ \"?b2fd\");\n\t\t\t\n\t\t\ttry {\n\t\t\t\tif (fs.existsSync(path)) {\n\t\t\t\t\treturn fs.readFileSync(path, charset);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tconsole.log(\"Path \" + path + \" does not exist.\");\n\t\t\t\t}\n\t\t\t} catch (e) {\n\t\t\t\tconsole.log(e);\n\t\t\t\treturn '';\n\t\t\t}\n\t\t}\n\t},\n\t\n\t/**\n\t * Parse the rules out from a .aff file.\n\t *\n\t * @param {String} data The contents of the affix file.\n\t * @returns object The rules from the file.\n\t */\n\t\n\t_parseAFF : function (data) {\n\t\tvar rules = {};\n\t\t\n\t\tvar line, subline, numEntries, lineParts;\n\t\tvar i, j, _len, _jlen;\n\t\t\n\t\t// Remove comment lines\n\t\tdata = this._removeAffixComments(data);\n\t\t\n\t\tvar lines = data.split(/\\r?\\n/);\n\t\t\n\t\tfor (i = 0, _len = lines.length; i < _len; i++) {\n\t\t\tline = lines[i];\n\t\t\t\n\t\t\tvar definitionParts = line.split(/\\s+/);\n\t\t\t\n\t\t\tvar ruleType = definitionParts[0];\n\t\t\t\n\t\t\tif (ruleType == \"PFX\" || ruleType == \"SFX\") {\n\t\t\t\tvar ruleCode = definitionParts[1];\n\t\t\t\tvar combineable = definitionParts[2];\n\t\t\t\tnumEntries = parseInt(definitionParts[3], 10);\n\t\t\t\t\n\t\t\t\tvar entries = [];\n\t\t\t\t\n\t\t\t\tfor (j = i + 1, _jlen = i + 1 + numEntries; j < _jlen; j++) {\n\t\t\t\t\tsubline = lines[j];\n\t\t\t\t\t\n\t\t\t\t\tlineParts = subline.split(/\\s+/);\n\t\t\t\t\tvar charactersToRemove = lineParts[2];\n\t\t\t\t\t\n\t\t\t\t\tvar additionParts = lineParts[3].split(\"/\");\n\t\t\t\t\t\n\t\t\t\t\tvar charactersToAdd = additionParts[0];\n\t\t\t\t\tif (charactersToAdd === \"0\") charactersToAdd = \"\";\n\t\t\t\t\t\n\t\t\t\t\tvar continuationClasses = this.parseRuleCodes(additionParts[1]);\n\t\t\t\t\t\n\t\t\t\t\tvar regexToMatch = lineParts[4];\n\t\t\t\t\t\n\t\t\t\t\tvar entry = {};\n\t\t\t\t\tentry.add = charactersToAdd;\n\t\t\t\t\t\n\t\t\t\t\tif (continuationClasses.length > 0) entry.continuationClasses = continuationClasses;\n\t\t\t\t\t\n\t\t\t\t\tif (regexToMatch !== \".\") {\n\t\t\t\t\t\tif (ruleType === \"SFX\") {\n\t\t\t\t\t\t\tentry.match = new RegExp(regexToMatch + \"$\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tentry.match = new RegExp(\"^\" + regexToMatch);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tif (charactersToRemove != \"0\") {\n\t\t\t\t\t\tif (ruleType === \"SFX\") {\n\t\t\t\t\t\t\tentry.remove = new RegExp(charactersToRemove  + \"$\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tentry.remove = charactersToRemove;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tentries.push(entry);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\trules[ruleCode] = { \"type\" : ruleType, \"combineable\" : (combineable == \"Y\"), \"entries\" : entries };\n\t\t\t\t\n\t\t\t\ti += numEntries;\n\t\t\t}\n\t\t\telse if (ruleType === \"COMPOUNDRULE\") {\n\t\t\t\tnumEntries = parseInt(definitionParts[1], 10);\n\t\t\t\t\n\t\t\t\tfor (j = i + 1, _jlen = i + 1 + numEntries; j < _jlen; j++) {\n\t\t\t\t\tline = lines[j];\n\t\t\t\t\t\n\t\t\t\t\tlineParts = line.split(/\\s+/);\n\t\t\t\t\tthis.compoundRules.push(lineParts[1]);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\ti += numEntries;\n\t\t\t}\n\t\t\telse if (ruleType === \"REP\") {\n\t\t\t\tlineParts = line.split(/\\s+/);\n\t\t\t\t\n\t\t\t\tif (lineParts.length === 3) {\n\t\t\t\t\tthis.replacementTable.push([ lineParts[1], lineParts[2] ]);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\t// ONLYINCOMPOUND\n\t\t\t\t// COMPOUNDMIN\n\t\t\t\t// FLAG\n\t\t\t\t// KEEPCASE\n\t\t\t\t// NEEDAFFIX\n\t\t\t\t\n\t\t\t\tthis.flags[ruleType] = definitionParts[1];\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn rules;\n\t},\n\t\n\t/**\n\t * Removes comment lines and then cleans up blank lines and trailing whitespace.\n\t *\n\t * @param {String} data The data from an affix file.\n\t * @return {String} The cleaned-up data.\n\t */\n\t\n\t_removeAffixComments : function (data) {\n\t\t// Remove comments\n\t\t// This used to remove any string starting with '#' up to the end of the line,\n\t\t// but some COMPOUNDRULE definitions include '#' as part of the rule.\n\t\t// I haven't seen any affix files that use comments on the same line as real data,\n\t\t// so I don't think this will break anything.\n\t\tdata = data.replace(/^\\s*#.*$/mg, \"\");\n\t\t\n\t\t// Trim each line\n\t\tdata = data.replace(/^\\s\\s*/m, '').replace(/\\s\\s*$/m, '');\n\t\t\n\t\t// Remove blank lines.\n\t\tdata = data.replace(/\\n{2,}/g, \"\\n\");\n\t\t\n\t\t// Trim the entire string\n\t\tdata = data.replace(/^\\s\\s*/, '').replace(/\\s\\s*$/, '');\n\t\t\n\t\treturn data;\n\t},\n\t\n\t/**\n\t * Parses the words out from the .dic file.\n\t *\n\t * @param {String} data The data from the dictionary file.\n\t * @returns object The lookup table containing all of the words and\n\t *                 word forms from the dictionary.\n\t */\n\t\n\t_parseDIC : function (data) {\n\t\tdata = this._removeDicComments(data);\n\t\t\n\t\tvar lines = data.split(/\\r?\\n/);\n\t\tvar dictionaryTable = {};\n\t\t\n\t\tfunction addWord(word, rules) {\n\t\t\t// Some dictionaries will list the same word multiple times with different rule sets.\n\t\t\tif (!dictionaryTable.hasOwnProperty(word)) {\n\t\t\t\tdictionaryTable[word] = null;\n\t\t\t}\n\t\t\t\n\t\t\tif (rules.length > 0) {\n\t\t\t\tif (dictionaryTable[word] === null) {\n\t\t\t\t\tdictionaryTable[word] = [];\n\t\t\t\t}\n\n\t\t\t\tdictionaryTable[word].push(rules);\n\t\t\t}\n\t\t}\n\t\t\n\t\t// The first line is the number of words in the dictionary.\n\t\tfor (var i = 1, _len = lines.length; i < _len; i++) {\n\t\t\tvar line = lines[i];\n\t\t\t\n\t\t\tif (!line) {\n\t\t\t\t// Ignore empty lines.\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tvar parts = line.split(\"/\", 2);\n\t\t\t\n\t\t\tvar word = parts[0];\n\n\t\t\t// Now for each affix rule, generate that form of the word.\n\t\t\tif (parts.length > 1) {\n\t\t\t\tvar ruleCodesArray = this.parseRuleCodes(parts[1]);\n\t\t\t\t\n\t\t\t\t// Save the ruleCodes for compound word situations.\n\t\t\t\tif (!(\"NEEDAFFIX\" in this.flags) || ruleCodesArray.indexOf(this.flags.NEEDAFFIX) == -1) {\n\t\t\t\t\taddWord(word, ruleCodesArray);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tfor (var j = 0, _jlen = ruleCodesArray.length; j < _jlen; j++) {\n\t\t\t\t\tvar code = ruleCodesArray[j];\n\t\t\t\t\t\n\t\t\t\t\tvar rule = this.rules[code];\n\t\t\t\t\t\n\t\t\t\t\tif (rule) {\n\t\t\t\t\t\tvar newWords = this._applyRule(word, rule);\n\t\t\t\t\t\t\n\t\t\t\t\t\tfor (var ii = 0, _iilen = newWords.length; ii < _iilen; ii++) {\n\t\t\t\t\t\t\tvar newWord = newWords[ii];\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\taddWord(newWord, []);\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tif (rule.combineable) {\n\t\t\t\t\t\t\t\tfor (var k = j + 1; k < _jlen; k++) {\n\t\t\t\t\t\t\t\t\tvar combineCode = ruleCodesArray[k];\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tvar combineRule = this.rules[combineCode];\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\tif (combineRule) {\n\t\t\t\t\t\t\t\t\t\tif (combineRule.combineable && (rule.type != combineRule.type)) {\n\t\t\t\t\t\t\t\t\t\t\tvar otherNewWords = this._applyRule(newWord, combineRule);\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\tfor (var iii = 0, _iiilen = otherNewWords.length; iii < _iiilen; iii++) {\n\t\t\t\t\t\t\t\t\t\t\t\tvar otherNewWord = otherNewWords[iii];\n\t\t\t\t\t\t\t\t\t\t\t\taddWord(otherNewWord, []);\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tif (code in this.compoundRuleCodes) {\n\t\t\t\t\t\tthis.compoundRuleCodes[code].push(word);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\taddWord(word.trim(), []);\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn dictionaryTable;\n\t},\n\t\n\t\n\t/**\n\t * Removes comment lines and then cleans up blank lines and trailing whitespace.\n\t *\n\t * @param {String} data The data from a .dic file.\n\t * @return {String} The cleaned-up data.\n\t */\n\t\n\t_removeDicComments : function (data) {\n\t\t// I can't find any official documentation on it, but at least the de_DE\n\t\t// dictionary uses tab-indented lines as comments.\n\t\t\n\t\t// Remove comments\n\t\tdata = data.replace(/^\\t.*$/mg, \"\");\n\t\t\n\t\treturn data;\n\t},\n\t\n\tparseRuleCodes : function (textCodes) {\n\t\tif (!textCodes) {\n\t\t\treturn [];\n\t\t}\n\t\telse if (!(\"FLAG\" in this.flags)) {\n\t\t\treturn textCodes.split(\"\");\n\t\t}\n\t\telse if (this.flags.FLAG === \"long\") {\n\t\t\tvar flags = [];\n\t\t\t\n\t\t\tfor (var i = 0, _len = textCodes.length; i < _len; i += 2) {\n\t\t\t\tflags.push(textCodes.substr(i, 2));\n\t\t\t}\n\t\t\t\n\t\t\treturn flags;\n\t\t}\n\t\telse if (this.flags.FLAG === \"num\") {\n\t\t\treturn textCodes.split(\",\");\n\t\t}\n\t},\n\t\n\t/**\n\t * Applies an affix rule to a word.\n\t *\n\t * @param {String} word The base word.\n\t * @param {Object} rule The affix rule.\n\t * @returns {String[]} The new words generated by the rule.\n\t */\n\t\n\t_applyRule : function (word, rule) {\n\t\tvar entries = rule.entries;\n\t\tvar newWords = [];\n\t\t\n\t\tfor (var i = 0, _len = entries.length; i < _len; i++) {\n\t\t\tvar entry = entries[i];\n\t\t\t\n\t\t\tif (!entry.match || word.match(entry.match)) {\n\t\t\t\tvar newWord = word;\n\t\t\t\t\n\t\t\t\tif (entry.remove) {\n\t\t\t\t\tnewWord = newWord.replace(entry.remove, \"\");\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (rule.type === \"SFX\") {\n\t\t\t\t\tnewWord = newWord + entry.add;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tnewWord = entry.add + newWord;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tnewWords.push(newWord);\n\t\t\t\t\n\t\t\t\tif (\"continuationClasses\" in entry) {\n\t\t\t\t\tfor (var j = 0, _jlen = entry.continuationClasses.length; j < _jlen; j++) {\n\t\t\t\t\t\tvar continuationRule = this.rules[entry.continuationClasses[j]];\n\t\t\t\t\t\t\n\t\t\t\t\t\tif (continuationRule) {\n\t\t\t\t\t\t\tnewWords = newWords.concat(this._applyRule(newWord, continuationRule));\n\t\t\t\t\t\t}\n\t\t\t\t\t\t/*\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t// This shouldn't happen, but it does, at least in the de_DE dictionary.\n\t\t\t\t\t\t\t// I think the author mistakenly supplied lower-case rule codes instead \n\t\t\t\t\t\t\t// of upper-case.\n\t\t\t\t\t\t}\n\t\t\t\t\t\t*/\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn newWords;\n\t},\n\t\n\t/**\n\t * Checks whether a word or a capitalization variant exists in the current dictionary.\n\t * The word is trimmed and several variations of capitalizations are checked.\n\t * If you want to check a word without any changes made to it, call checkExact()\n\t *\n\t * @see http://blog.stevenlevithan.com/archives/faster-trim-javascript re:trimming function\n\t *\n\t * @param {String} aWord The word to check.\n\t * @returns {Boolean}\n\t */\n\t\n\tcheck : function (aWord) {\n\t\tif (!this.loaded) {\n\t\t\tthrow \"Dictionary not loaded.\";\n\t\t}\n\t\t\n\t\t// Remove leading and trailing whitespace\n\t\tvar trimmedWord = aWord.replace(/^\\s\\s*/, '').replace(/\\s\\s*$/, '');\n\t\t\n\t\tif (this.checkExact(trimmedWord)) {\n\t\t\treturn true;\n\t\t}\n\t\t\n\t\t// The exact word is not in the dictionary.\n\t\tif (trimmedWord.toUpperCase() === trimmedWord) {\n\t\t\t// The word was supplied in all uppercase.\n\t\t\t// Check for a capitalized form of the word.\n\t\t\tvar capitalizedWord = trimmedWord[0] + trimmedWord.substring(1).toLowerCase();\n\t\t\t\n\t\t\tif (this.hasFlag(capitalizedWord, \"KEEPCASE\")) {\n\t\t\t\t// Capitalization variants are not allowed for this word.\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\t\n\t\t\tif (this.checkExact(capitalizedWord)) {\n\t\t\t\t// The all-caps word is a capitalized word spelled correctly.\n\t\t\t\treturn true;\n\t\t\t}\n\n\t\t\tif (this.checkExact(trimmedWord.toLowerCase())) {\n\t\t\t\t// The all-caps is a lowercase word spelled correctly.\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\t\n\t\tvar uncapitalizedWord = trimmedWord[0].toLowerCase() + trimmedWord.substring(1);\n\t\t\n\t\tif (uncapitalizedWord !== trimmedWord) {\n\t\t\tif (this.hasFlag(uncapitalizedWord, \"KEEPCASE\")) {\n\t\t\t\t// Capitalization variants are not allowed for this word.\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\t\n\t\t\t// Check for an uncapitalized form\n\t\t\tif (this.checkExact(uncapitalizedWord)) {\n\t\t\t\t// The word is spelled correctly but with the first letter capitalized.\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn false;\n\t},\n\t\n\t/**\n\t * Checks whether a word exists in the current dictionary.\n\t *\n\t * @param {String} word The word to check.\n\t * @returns {Boolean}\n\t */\n\t\n\tcheckExact : function (word) {\n\t\tif (!this.loaded) {\n\t\t\tthrow \"Dictionary not loaded.\";\n\t\t}\n\n\t\tvar ruleCodes = this.dictionaryTable[word];\n\t\t\n\t\tvar i, _len;\n\t\t\n\t\tif (typeof ruleCodes === 'undefined') {\n\t\t\t// Check if this might be a compound word.\n\t\t\tif (\"COMPOUNDMIN\" in this.flags && word.length >= this.flags.COMPOUNDMIN) {\n\t\t\t\tfor (i = 0, _len = this.compoundRules.length; i < _len; i++) {\n\t\t\t\t\tif (word.match(this.compoundRules[i])) {\n\t\t\t\t\t\treturn true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse if (ruleCodes === null) {\n\t\t\t// a null (but not undefined) value for an entry in the dictionary table\n\t\t\t// means that the word is in the dictionary but has no flags.\n\t\t\treturn true;\n\t\t}\n\t\telse if (typeof ruleCodes === 'object') { // this.dictionary['hasOwnProperty'] will be a function.\n\t\t\tfor (i = 0, _len = ruleCodes.length; i < _len; i++) {\n\t\t\t\tif (!this.hasFlag(word, \"ONLYINCOMPOUND\", ruleCodes[i])) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn false;\n\t},\n\t\n\t/**\n\t * Looks up whether a given word is flagged with a given flag.\n\t *\n\t * @param {String} word The word in question.\n\t * @param {String} flag The flag in question.\n\t * @return {Boolean}\n\t */\n\t \n\thasFlag : function (word, flag, wordFlags) {\n\t\tif (!this.loaded) {\n\t\t\tthrow \"Dictionary not loaded.\";\n\t\t}\n\n\t\tif (flag in this.flags) {\n\t\t\tif (typeof wordFlags === 'undefined') {\n\t\t\t\twordFlags = Array.prototype.concat.apply([], this.dictionaryTable[word]);\n\t\t\t}\n\t\t\t\n\t\t\tif (wordFlags && wordFlags.indexOf(this.flags[flag]) !== -1) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn false;\n\t},\n\t\n\t/**\n\t * Returns a list of suggestions for a misspelled word.\n\t *\n\t * @see http://www.norvig.com/spell-correct.html for the basis of this suggestor.\n\t * This suggestor is primitive, but it works.\n\t *\n\t * @param {String} word The misspelling.\n\t * @param {Number} [limit=5] The maximum number of suggestions to return.\n\t * @returns {String[]} The array of suggestions.\n\t */\n\t\n\talphabet : \"\",\n\t\n\tsuggest : function (word, limit) {\n\t\tif (!this.loaded) {\n\t\t\tthrow \"Dictionary not loaded.\";\n\t\t}\n\n\t\tlimit = limit || 5;\n\n\t\tif (this.memoized.hasOwnProperty(word)) {\n\t\t\tvar memoizedLimit = this.memoized[word]['limit'];\n\n\t\t\t// Only return the cached list if it's big enough or if there weren't enough suggestions\n\t\t\t// to fill a smaller limit.\n\t\t\tif (limit <= memoizedLimit || this.memoized[word]['suggestions'].length < memoizedLimit) {\n\t\t\t\treturn this.memoized[word]['suggestions'].slice(0, limit);\n\t\t\t}\n\t\t}\n\t\t\n\t\tif (this.check(word)) return [];\n\t\t\n\t\t// Check the replacement table.\n\t\tfor (var i = 0, _len = this.replacementTable.length; i < _len; i++) {\n\t\t\tvar replacementEntry = this.replacementTable[i];\n\t\t\t\n\t\t\tif (word.indexOf(replacementEntry[0]) !== -1) {\n\t\t\t\tvar correctedWord = word.replace(replacementEntry[0], replacementEntry[1]);\n\t\t\t\t\n\t\t\t\tif (this.check(correctedWord)) {\n\t\t\t\t\treturn [ correctedWord ];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\tvar self = this;\n\t\tself.alphabet = \"abcdefghijklmnopqrstuvwxyz\";\n\t\t\n\t\t/*\n\t\tif (!self.alphabet) {\n\t\t\t// Use the alphabet as implicitly defined by the words in the dictionary.\n\t\t\tvar alphaHash = {};\n\t\t\t\n\t\t\tfor (var i in self.dictionaryTable) {\n\t\t\t\tfor (var j = 0, _len = i.length; j < _len; j++) {\n\t\t\t\t\talphaHash[i[j]] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tfor (var i in alphaHash) {\n\t\t\t\tself.alphabet += i;\n\t\t\t}\n\t\t\t\n\t\t\tvar alphaArray = self.alphabet.split(\"\");\n\t\t\talphaArray.sort();\n\t\t\tself.alphabet = alphaArray.join(\"\");\n\t\t}\n\t\t*/\n\t\t\n\t\t/**\n\t\t * Returns a hash keyed by all of the strings that can be made by making a single edit to the word (or words in) `words`\n\t\t * The value of each entry is the number of unique ways that the resulting word can be made.\n\t\t *\n\t\t * @arg mixed words Either a hash keyed by words or a string word to operate on.\n\t\t * @arg bool known_only Whether this function should ignore strings that are not in the dictionary.\n\t\t */\n\t\tfunction edits1(words, known_only) {\n\t\t\tvar rv = {};\n\t\t\t\n\t\t\tvar i, j, _iilen, _len, _jlen, _edit;\n\n\t\t\tvar alphabetLength = self.alphabet.length;\n\t\t\t\n\t\t\tif (typeof words == 'string') {\n\t\t\t\tvar word = words;\n\t\t\t\twords = {};\n\t\t\t\twords[word] = true;\n\t\t\t}\n\n\t\t\tfor (var word in words) {\n\t\t\t\tfor (i = 0, _len = word.length + 1; i < _len; i++) {\n\t\t\t\t\tvar s = [ word.substring(0, i), word.substring(i) ];\n\t\t\t\t\n\t\t\t\t\t// Remove a letter.\n\t\t\t\t\tif (s[1]) {\n\t\t\t\t\t\t_edit = s[0] + s[1].substring(1);\n\n\t\t\t\t\t\tif (!known_only || self.check(_edit)) {\n\t\t\t\t\t\t\tif (!(_edit in rv)) {\n\t\t\t\t\t\t\t\trv[_edit] = 1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\trv[_edit] += 1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\t// Transpose letters\n\t\t\t\t\t// Eliminate transpositions of identical letters\n\t\t\t\t\tif (s[1].length > 1 && s[1][1] !== s[1][0]) {\n\t\t\t\t\t\t_edit = s[0] + s[1][1] + s[1][0] + s[1].substring(2);\n\n\t\t\t\t\t\tif (!known_only || self.check(_edit)) {\n\t\t\t\t\t\t\tif (!(_edit in rv)) {\n\t\t\t\t\t\t\t\trv[_edit] = 1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\trv[_edit] += 1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tif (s[1]) {\n\t\t\t\t\t\t// Replace a letter with another letter.\n\n\t\t\t\t\t\tvar lettercase = (s[1].substring(0,1).toUpperCase() === s[1].substring(0,1)) ? 'uppercase' : 'lowercase';\n\n\t\t\t\t\t\tfor (j = 0; j < alphabetLength; j++) {\n\t\t\t\t\t\t\tvar replacementLetter = self.alphabet[j];\n\n\t\t\t\t\t\t\t// Set the case of the replacement letter to the same as the letter being replaced.\n\t\t\t\t\t\t\tif ( 'uppercase' === lettercase ) {\n\t\t\t\t\t\t\t\treplacementLetter = replacementLetter.toUpperCase();\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// Eliminate replacement of a letter by itself\n\t\t\t\t\t\t\tif (replacementLetter != s[1].substring(0,1)){\n\t\t\t\t\t\t\t\t_edit = s[0] + replacementLetter + s[1].substring(1);\n\n\t\t\t\t\t\t\t\tif (!known_only || self.check(_edit)) {\n\t\t\t\t\t\t\t\t\tif (!(_edit in rv)) {\n\t\t\t\t\t\t\t\t\t\trv[_edit] = 1;\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\t\t\trv[_edit] += 1;\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tif (s[1]) {\n\t\t\t\t\t\t// Add a letter between each letter.\n\t\t\t\t\t\tfor (j = 0; j < alphabetLength; j++) {\n\t\t\t\t\t\t\t// If the letters on each side are capitalized, capitalize the replacement.\n\t\t\t\t\t\t\tvar lettercase = (s[0].substring(-1).toUpperCase() === s[0].substring(-1) && s[1].substring(0,1).toUpperCase() === s[1].substring(0,1)) ? 'uppercase' : 'lowercase';\n\n\t\t\t\t\t\t\tvar replacementLetter = self.alphabet[j];\n\n\t\t\t\t\t\t\tif ( 'uppercase' === lettercase ) {\n\t\t\t\t\t\t\t\treplacementLetter = replacementLetter.toUpperCase();\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t_edit = s[0] + replacementLetter + s[1];\n\n\t\t\t\t\t\t\tif (!known_only || self.check(_edit)) {\n\t\t\t\t\t\t\t\tif (!(_edit in rv)) {\n\t\t\t\t\t\t\t\t\trv[_edit] = 1;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\t\trv[_edit] += 1;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\treturn rv;\n\t\t}\n\n\t\tfunction correct(word) {\n\t\t\t// Get the edit-distance-1 and edit-distance-2 forms of this word.\n\t\t\tvar ed1 = edits1(word);\n\t\t\tvar ed2 = edits1(ed1, true);\n\t\t\t\n\t\t\t// Sort the edits based on how many different ways they were created.\n\t\t\tvar weighted_corrections = ed2;\n\t\t\t\n\t\t\tfor (var ed1word in ed1) {\n\t\t\t\tif (!self.check(ed1word)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tif (ed1word in weighted_corrections) {\n\t\t\t\t\tweighted_corrections[ed1word] += ed1[ed1word];\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tweighted_corrections[ed1word] = ed1[ed1word];\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tvar i, _len;\n\n\t\t\tvar sorted_corrections = [];\n\t\t\t\n\t\t\tfor (i in weighted_corrections) {\n\t\t\t\tif (weighted_corrections.hasOwnProperty(i)) {\n\t\t\t\t\tsorted_corrections.push([ i, weighted_corrections[i] ]);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfunction sorter(a, b) {\n\t\t\t\tvar a_val = a[1];\n\t\t\t\tvar b_val = b[1];\n\t\t\t\tif (a_val < b_val) {\n\t\t\t\t\treturn -1;\n\t\t\t\t} else if (a_val > b_val) {\n\t\t\t\t\treturn 1;\n\t\t\t\t}\n\t\t\t\t// @todo If a and b are equally weighted, add our own weight based on something like the key locations on this language's default keyboard.\n\t\t\t\treturn b[0].localeCompare(a[0]);\n\t\t\t}\n\t\t\t\n\t\t\tsorted_corrections.sort(sorter).reverse();\n\n\t\t\tvar rv = [];\n\n\t\t\tvar capitalization_scheme = \"lowercase\";\n\t\t\t\n\t\t\tif (word.toUpperCase() === word) {\n\t\t\t\tcapitalization_scheme = \"uppercase\";\n\t\t\t}\n\t\t\telse if (word.substr(0, 1).toUpperCase() + word.substr(1).toLowerCase() === word) {\n\t\t\t\tcapitalization_scheme = \"capitalized\";\n\t\t\t}\n\t\t\t\n\t\t\tvar working_limit = limit;\n\n\t\t\tfor (i = 0; i < Math.min(working_limit, sorted_corrections.length); i++) {\n\t\t\t\tif (\"uppercase\" === capitalization_scheme) {\n\t\t\t\t\tsorted_corrections[i][0] = sorted_corrections[i][0].toUpperCase();\n\t\t\t\t}\n\t\t\t\telse if (\"capitalized\" === capitalization_scheme) {\n\t\t\t\t\tsorted_corrections[i][0] = sorted_corrections[i][0].substr(0, 1).toUpperCase() + sorted_corrections[i][0].substr(1);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (!self.hasFlag(sorted_corrections[i][0], \"NOSUGGEST\") && rv.indexOf(sorted_corrections[i][0]) == -1) {\n\t\t\t\t\trv.push(sorted_corrections[i][0]);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\t// If one of the corrections is not eligible as a suggestion , make sure we still return the right number of suggestions.\n\t\t\t\t\tworking_limit++;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn rv;\n\t\t}\n\t\t\n\t\tthis.memoized[word] = {\n\t\t\t'suggestions': correct(word),\n\t\t\t'limit': limit\n\t\t};\n\n\t\treturn this.memoized[word]['suggestions'];\n\t}\n};\n})();\n\n// Support for use as a node.js module.\nif (true) {\n\tmodule.exports = Typo;\n}\n\n\n//# sourceURL=webpack://JB_task/./node_modules/typo-js/typo.js?");

/***/ })

}]);